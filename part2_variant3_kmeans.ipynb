{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NX-421 Mini-Project â€” Part 2 (Variant 3: K-means)\n",
        "\n",
        "This notebook performs the MVPA K-means variant using the preprocessed fMRI time series (one volume = one sample).\n",
        "It follows the style of the course labs and your teammates' preprocessing.\n",
        "\n",
        "We will:\n",
        "- Apply K-means clustering on volumes treated as samples (1 volume = 1 sample).\n",
        "- Select number of clusters and justify via elbow (inertia) and silhouette analyses; visualize centroids.\n",
        "- Compute pairwise similarity of the first 5 centroids and report the matrix.\n",
        "\n",
        "Assumptions:\n",
        "- You already have a preprocessed 4D BOLD image (concatenated runs, motion-corrected, smoothed) as in Part 1.\n",
        "- We avoid GLM completely; this is data-driven MVPA.\n",
        "- For memory/computation, we optionally reduce to the top-variance voxels (configurable).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "Set the paths and options below before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, os.path as op\n",
        "\n",
        "# Paths\n",
        "DATA_ROOT = op.abspath('NSSP-Mini-Project-1/data')  # adjust to your VM\n",
        "OUTPUT_DIR = op.abspath('NSSP-Mini-Project-1/results_part2_kmeans')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Preprocessed concatenated 4D BOLD (same used for Part 1 GLM)\n",
        "FUNC_IMG = op.join(DATA_ROOT, 'sub-101410_task-motor_preproc_concat_bold.nii.gz')\n",
        "\n",
        "# K-means configuration\n",
        "K_RANGE = list(range(2, 13))   # explore 2..12 for elbow/silhouette\n",
        "N_CLUSTERS = 8                 # final chosen K (adjust after inspecting metrics)\n",
        "USE_MINIBATCH = False          # set True to use MiniBatchKMeans for speed\n",
        "RANDOM_STATE = 42\n",
        "N_INIT = 'auto'                # sklearn >=1.4, else set to 10\n",
        "\n",
        "# Feature preprocessing\n",
        "STANDARDIZE = True             # z-score each voxel across time\n",
        "DETREND = True\n",
        "MAX_VOXELS = 50000             # reduce to top-variance voxels if more than this (set None to disable)\n",
        "\n",
        "# Plotting\n",
        "Z_CUTS = 7                     # number of axial cuts in figures\n",
        "THRESH = None                  # optional threshold for centroid display (e.g., 1.0); set None for auto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports aligned with course/labs style\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from nilearn import plotting, image\n",
        "from nilearn.datasets import load_mni152_template\n",
        "\n",
        "try:\n",
        "    from nilearn.maskers import NiftiMasker\n",
        "except Exception:\n",
        "    from nilearn.input_data import NiftiMasker\n",
        "\n",
        "from nilearn.masking import compute_epi_mask\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load functional data and compute brain mask\n",
        "We treat each volume as one sample. We derive a mask from the EPI (compute_epi_mask), and use `NiftiMasker` to vectorize the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert op.isfile(FUNC_IMG), f'Functional image not found: {FUNC_IMG}'\n",
        "fmri_img = nib.load(FUNC_IMG)\n",
        "n_scans = fmri_img.shape[-1]\n",
        "zooms = fmri_img.header.get_zooms()\n",
        "TR = float(zooms[3]) if len(zooms) > 3 else 0.72\n",
        "print(f'Loaded functional: {FUNC_IMG}')\n",
        "print(f'Shape: {fmri_img.shape}, TR: {TR:.3f} s, n_scans: {n_scans}')\n",
        "\n",
        "# Compute brain mask from EPI\n",
        "mask_img = compute_epi_mask(fmri_img)\n",
        "mask_img.to_filename(op.join(OUTPUT_DIR, 'mask_epi.nii.gz'))\n",
        "\n",
        "# Build masker\n",
        "standardize_opt = 'zscore' if STANDARDIZE else False\n",
        "# Newer nilearn uses 'zscore' and 'zscore_sample'. We'll default to 'zscore' across all scans.\n",
        "masker = NiftiMasker(mask_img=mask_img, standardize=standardize_opt, detrend=DETREND)\n",
        "X = masker.fit_transform(fmri_img)  # shape (n_scans, n_voxels)\n",
        "n_vox = X.shape[1]\n",
        "print(f'Data matrix: {X.shape} (samples x voxels)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: reduce to top-variance voxels\n",
        "For speed and memory, we can select the top-variance voxels across time. This does not change the \"one volume = one sample\" setup; it reduces feature dimensionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_reduction = (MAX_VOXELS is not None) and (n_vox > MAX_VOXELS)\n",
        "if use_reduction:\n",
        "    vars_ = X.var(axis=0)\n",
        "    keep_idx = np.argsort(vars_)[-int(MAX_VOXELS):]  # top-variance voxels\n",
        "    X_red = X[:, keep_idx]\n",
        "    print(f'Reduced features from {n_vox} to {X_red.shape[1]} by variance selection.')\n",
        "else:\n",
        "    X_red = X\n",
        "    keep_idx = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select number of clusters\n",
        "We compute inertia (elbow) and silhouette for a range of K, then choose `N_CLUSTERS`.\n",
        "Use these plots to justify your choice in the report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inertias = []\n",
        "silhouettes = []\n",
        "for k in K_RANGE:\n",
        "    if USE_MINIBATCH:\n",
        "        km = MiniBatchKMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=N_INIT, batch_size=256)\n",
        "    else:\n",
        "        km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=N_INIT)\n",
        "    labels = km.fit_predict(X_red)\n",
        "    inertias.append(km.inertia_)\n",
        "    try:\n",
        "        silhouettes.append(silhouette_score(X_red, labels))\n",
        "    except Exception:\n",
        "        silhouettes.append(np.nan)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
        "ax[0].plot(K_RANGE, inertias, marker='o')\n",
        "ax[0].set_title('Elbow (Inertia)')\n",
        "ax[0].set_xlabel('K')\n",
        "ax[0].set_ylabel('Inertia')\n",
        "ax[1].plot(K_RANGE, silhouettes, marker='o', color='green')\n",
        "ax[1].set_title('Silhouette Score')\n",
        "ax[1].set_xlabel('K')\n",
        "ax[1].set_ylabel('Silhouette')\n",
        "plt.tight_layout()\n",
        "fig.savefig(op.join(OUTPUT_DIR, 'k_selection_elbow_silhouette.png'), dpi=150)\n",
        "plt.show()\n",
        "pd.DataFrame({'K': K_RANGE, 'inertia': inertias, 'silhouette': silhouettes}).to_csv(\n",
        "    op.join(OUTPUT_DIR, 'k_selection_metrics.csv'), index=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final K-means fit and centroid maps\n",
        "Run K-means with your chosen `N_CLUSTERS`, then reconstruct each centroid as a 3D volume and visualize (axial view).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if USE_MINIBATCH:\n",
        "    kmodel = MiniBatchKMeans(n_clusters=N_CLUSTERS, random_state=RANDOM_STATE, n_init=N_INIT, batch_size=256)\n",
        "else:\n",
        "    kmodel = KMeans(n_clusters=N_CLUSTERS, random_state=RANDOM_STATE, n_init=N_INIT)\n",
        "labels = kmodel.fit_predict(X_red)\n",
        "centroids_red = kmodel.cluster_centers_  # shape (K, n_features_reduced)\n",
        "\n",
        "# Save labels per-volume\n",
        "labels_path = op.join(OUTPUT_DIR, f'kmeans_labels_K{N_CLUSTERS}.csv')\n",
        "pd.DataFrame({'volume_idx': np.arange(n_scans), 'label': labels}).to_csv(labels_path, index=False)\n",
        "print('Saved labels to:', labels_path)\n",
        "\n",
        "# Prepare MNI background if available\n",
        "try:\n",
        "    bg_img = load_mni152_template()\n",
        "except Exception:\n",
        "    bg_img = None\n",
        "\n",
        "# Helper to build full-length centroid (if reduced)")
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def full_centroid_from_reduced(c_red, total_vox, keep_idx):\n",
        "    if keep_idx is None:\n",
        "        return c_red\n",
        "    c_full = np.zeros((total_vox,), dtype=np.float32)\n",
        "    c_full[keep_idx] = c_red\n",
        "    return c_full\n",
        "\n",
        "# Visualize and save centroid maps\n",
        "centroid_imgs = []\n",
        "for i in range(N_CLUSTERS):\n",
        "    c_red = centroids_red[i]\n",
        "    c_full = full_centroid_from_reduced(c_red, n_vox, keep_idx)\n",
        "    # inverse_transform expects shape (n_samples, n_features)\n",
        "    c_img = masker.inverse_transform(c_full[np.newaxis, :])\n",
        "    centroid_imgs.append(c_img)\n",
        "    out_nii = op.join(OUTPUT_DIR, f'centroid_K{N_CLUSTERS}_{i:02d}.nii.gz')\n",
        "    c_img.to_filename(out_nii)\n",
        "    # Plot axial view\n",
        "    display = plotting.plot_stat_map(\n",
        "        c_img, bg_img=bg_img, display_mode='z', cut_coords=Z_CUTS, threshold=THRESH,\n",
        "        title=f'Centroid {i} (K={N_CLUSTERS})'\n",
        "    )\n",
        "    display.savefig(op.join(OUTPUT_DIR, f'centroid_K{N_CLUSTERS}_{i:02d}.png'))\n",
        "    display.close()\n",
        "print(f'Saved {len(centroid_imgs)} centroid images.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pairwise similarity of first 5 centroids\n",
        "We compute Pearson correlation and cosine similarity between the first up to 5 centroids and report matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = min(5, N_CLUSTERS)\n",
        "C = centroids_red[:m]  # shape (m, n_features_reduced)\n",
        "# Pearson correlation across voxels\n",
        "corr_mat = np.corrcoef(C)  # correlates rows\n",
        "# Cosine similarity\n",
        "cos_mat = cosine_similarity(C)\n",
        "\n",
        "corr_df = pd.DataFrame(corr_mat, index=[f'C{i}' for i in range(m)], columns=[f'C{i}' for i in range(m)])\n",
        "cos_df = pd.DataFrame(cos_mat, index=[f'C{i}' for i in range(m)], columns=[f'C{i}' for i in range(m)])\n",
        "corr_df.to_csv(op.join(OUTPUT_DIR, f'centroids_corr_K{N_CLUSTERS}_first{m}.csv'))\n",
        "cos_df.to_csv(op.join(OUTPUT_DIR, f'centroids_cosine_K{N_CLUSTERS}_first{m}.csv'))\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "im0 = ax[0].imshow(corr_mat, vmin=-1, vmax=1, cmap='coolwarm')\n",
        "ax[0].set_title('Centroids Pearson Corr')\n",
        "ax[0].set_xticks(range(m)); ax[0].set_yticks(range(m))\n",
        "ax[0].set_xticklabels([f'C{i}' for i in range(m)])\n",
        "ax[0].set_yticklabels([f'C{i}' for i in range(m)])\n",
        "plt.colorbar(im0, ax=ax[0], fraction=0.046, pad=0.04)\n",
        "im1 = ax[1].imshow(cos_mat, vmin=0, vmax=1, cmap='viridis')\n",
        "ax[1].set_title('Centroids Cosine Sim')\n",
        "ax[1].set_xticks(range(m)); ax[1].set_yticks(range(m))\n",
        "ax[1].set_xticklabels([f'C{i}' for i in range(m)])\n",
        "ax[1].set_yticklabels([f'C{i}' for i in range(m)])\n",
        "plt.colorbar(im1, ax=ax[1], fraction=0.046, pad=0.04)\n",
        "plt.tight_layout()\n",
        "plt.savefig(op.join(OUTPUT_DIR, f'centroids_similarity_K{N_CLUSTERS}_first{m}.png'), dpi=150)\n",
        "plt.show()\n",
        "corr_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes for the report\n",
        "- Justify chosen K using the elbow and silhouette plots saved as `k_selection_elbow_silhouette.png`.\n",
        "- Include axial-view images of every centroid (files `centroid_K.._..png`).\n",
        "- Include the pairwise similarity matrix (CSV and PNG).\n",
        "- Optionally discuss which centroids resemble known motor networks or overlap with GLM activations (Part 1).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

