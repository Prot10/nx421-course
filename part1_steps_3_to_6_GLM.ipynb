{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NX-421 Mini-Project — Part 1 (Steps 3–6)\n",
        "\n",
        "This notebook continues after preprocessing and follows the same approach as the labs and teammates' notebooks.\n",
        "It assumes you already have a preprocessed 4D fMRI time series for subject 101410 (concatenated runs, motion-corrected, smoothed) and event files.\n",
        "\n",
        "We will:\n",
        "- Build and visualize the experimental design matrix (3).\n",
        "- Fit a first-level GLM and report statistical maps per task regressor (4).\n",
        "- Define and apply a hand vs. foot contrast, and save the contrast map (5).\n",
        "- Overlay the contrast map with the AAL atlas and report regions with maximal contrast (6).\n",
        "\n",
        "Notes:\n",
        "- Keep parameters and functions in line with nx421-course/Week05 GLM lab (nilearn FirstLevelModel, spm HRF, ar1 noise).\n",
        "- This notebook does not re-run preprocessing. Point `FUNC_IMG` to your final preprocessed 4D image.\n",
        "- Adjust paths in the Parameters cell below to match your VM and data layout.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "Set input/output paths here.\n",
        "- `FUNC_IMG`: final preprocessed 4D BOLD timeseries used for GLM.\n",
        "- `EVENT_FILES`: list of per-run event CSVs, each with `onset`, `duration`, `trial_type`.\n",
        "  If you already have a single concatenated events CSV, pass it as a single-item list.\n",
        "- If you concatenated runs into one functional image, you must offset onsets of later runs before GLM.\n",
        "  Provide either `RUN_IMG_FILES` (original per-run 4D files) or `RUN_SCANS` (n_volumes per run) so we can compute offsets based on TR.\n",
        "- If motion confounds are available (e.g., MCFLIRT `.par` to regress), point `CONFOUNDS_TSV` to a TSV or CSV you prepared; otherwise leave `None`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, os.path as op\n",
        "\n",
        "# Adjust these paths for your VM\n",
        "DATA_ROOT = op.abspath('NSSP-Mini-Project-1/data')  # change if needed\n",
        "OUTPUT_DIR = op.abspath('NSSP-Mini-Project-1/results_part1_glm')\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Final preprocessed 4D image (concatenated, motion-corrected, smoothed).\n",
        "# Example placeholder; update to your produced filename:\n",
        "FUNC_IMG = op.join(DATA_ROOT, 'sub-101410_task-motor_preproc_concat_bold.nii.gz')\n",
        "\n",
        "# Event files per run. If you already have a single concatenated events file,\n",
        "# pass it as a single-item list and leave RUN_IMG_FILES/RUN_SCANS empty.\n",
        "EVENT_FILES = [\n",
        "    op.join(DATA_ROOT, 'sub-101410_task-motor_run-LR_events.csv'),\n",
        "    op.join(DATA_ROOT, 'sub-101410_task-motor_run-RL_events.csv'),\n",
        "]\n",
        "\n",
        "# Optional: original per-run 4D images to infer run lengths for onset offsets.\n",
        "# If provided, we use these to compute offsets. Otherwise, use RUN_SCANS or assume events are already concatenated.\n",
        "RUN_IMG_FILES = [\n",
        "    op.join(DATA_ROOT, 'tfMRI_MOTOR_LR.nii.gz'),\n",
        "    op.join(DATA_ROOT, 'tfMRI_MOTOR_RL.nii.gz'),\n",
        "]\n",
        "\n",
        "# Alternative: provide number of scans per run (if RUN_IMG_FILES are not available).\n",
        "RUN_SCANS = []  # e.g., [284, 284]\n",
        "\n",
        "# Optional confounds file (e.g., motion regressors). Leave as None if not used.\n",
        "CONFOUNDS_TSV = None  # op.join(DATA_ROOT, 'sub-101410_task-motor_confounds.tsv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports consistent with Week05 GLM lab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
        "from nilearn import plotting, image\n",
        "from nilearn.datasets import fetch_atlas_aal, load_mni152_template\n",
        "\n",
        "# Masker import for region-wise extraction (new vs old nilearn)\n",
        "try:\n",
        "    from nilearn.maskers import NiftiLabelsMasker\n",
        "except Exception:\n",
        "    from nilearn.input_data import NiftiLabelsMasker\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load functional image and TR\n",
        "We read the preprocessed concatenated 4D BOLD and extract TR from header.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert op.isfile(FUNC_IMG), f'Functional image not found: {FUNC_IMG}'\n",
        "fmri_img = nib.load(FUNC_IMG)\n",
        "n_scans = fmri_img.shape[-1]\n",
        "zooms = fmri_img.header.get_zooms()\n",
        "TR = float(zooms[3]) if len(zooms) > 3 else 0.72  # default to 0.72s if missing\n",
        "print(f'Loaded functional: {FUNC_IMG}')\n",
        "print(f'Shape: {fmri_img.shape}, TR: {TR:.3f} s, n_scans: {n_scans}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load events and adjust onsets for concatenation\n",
        "- Expects columns: `onset`, `duration`, `trial_type`.\n",
        "- If multiple runs provided, onsets for subsequent runs are offset by the preceding run durations (`n_scans_run * TR`).\n",
        "- If neither `RUN_IMG_FILES` nor `RUN_SCANS` is given, events are assumed already concatenated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _load_events(paths):\n",
        "    evs = []\n",
        "    for idx, p in enumerate(paths):\n",
        "        assert op.isfile(p), f'Events file not found: {p}'\n",
        "        df = pd.read_csv(p)\n",
        "        required = {'onset','duration','trial_type'}\n",
        "        missing = required - set(df.columns)\n",
        "        if missing:\n",
        "            raise ValueError(f'Missing columns in {p}: {missing}')\n",
        "        df = df[['onset','duration','trial_type']].copy()\n",
        "        df['run_idx'] = idx\n",
        "        evs.append(df)\n",
        "    return evs\n",
        "\n",
        "def _get_run_scans(run_img_files, fallback_scans):\n",
        "    scans = []\n",
        "    if run_img_files and all(op.isfile(r) for r in run_img_files):\n",
        "        for r in run_img_files:\n",
        "            img = nib.load(r)\n",
        "            scans.append(img.shape[-1])\n",
        "    elif fallback_scans:\n",
        "        scans = list(fallback_scans)\n",
        "    return scans\n",
        "\n",
        "def adjust_events_for_concatenation(events_list, run_scans, tr):\n",
        "    # If single events file, nothing to adjust\n",
        "    if len(events_list) == 1:\n",
        "        return events_list[0].drop(columns=['run_idx'], errors='ignore').reset_index(drop=True)\n",
        "    # If multiple, compute cumulative onset offsets\n",
        "    if not run_scans or len(run_scans) != len(events_list):\n",
        "        # Assume already concatenated\n",
        "        print('No run lengths provided; assuming events are already concatenated.')\n",
        "        return pd.concat(events_list, ignore_index=True).drop(columns=['run_idx'], errors='ignore').reset_index(drop=True)\n",
        "    offsets = np.cumsum([0] + [int(s)*tr for s in run_scans[:-1]]).astype(float)\n",
        "    adjusted = []\n",
        "    for df in events_list:\n",
        "        ridx = int(df['run_idx'].iloc[0])\n",
        "        off = float(offsets[ridx])\n",
        "        tmp = df.copy()\n",
        "        tmp['onset'] = tmp['onset'] + off\n",
        "        adjusted.append(tmp)\n",
        "    out = pd.concat(adjusted, ignore_index=True)\n",
        "    return out.drop(columns=['run_idx']).reset_index(drop=True)\n",
        "\n",
        "raw_events = _load_events(EVENT_FILES)\n",
        "run_scans = _get_run_scans(RUN_IMG_FILES, RUN_SCANS)\n",
        "events = adjust_events_for_concatenation(raw_events, run_scans, TR)\n",
        "print('Unique trial types:', sorted(events['trial_type'].unique()))\n",
        "events.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Design matrix\n",
        "Following the Week05 lab, we construct the design matrix using SPM HRF, AR(1) noise, and cosine drift (high-pass=0.01 Hz).\n",
        "We display the design matrix for reporting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_design_matrix\n",
        "\n",
        "frame_times = np.arange(n_scans) * TR\n",
        "design_matrix = make_first_level_design_matrix(\n",
        "    frame_times,\n",
        "    events=events,\n",
        "    hrf_model='spm',\n",
        "    drift_model='cosine',\n",
        "    high_pass=0.01\n",
        ")\n",
        "\n",
        "# Optionally add confounds (e.g., motion params, outlier regressors) as extra columns\n",
        "if CONFOUNDS_TSV is not None and op.isfile(CONFOUNDS_TSV):\n",
        "    conf = pd.read_csv(CONFOUNDS_TSV, sep='\t' if CONFOUNDS_TSV.endswith('.tsv') else ',')\n",
        "    # Keep numeric columns only and align rows to n_scans\n",
        "    conf = conf.select_dtypes(include=[np.number])\n",
        "    if conf.shape[0] != n_scans:\n",
        "        print(f'Warning: confounds rows ({conf.shape[0]}) != n_scans ({n_scans}); attempting to trim/pad.')\n",
        "        conf = conf.iloc[:n_scans, :]\n",
        "        if conf.shape[0] < n_scans:\n",
        "            # pad with zeros\n",
        "            pad_rows = n_scans - conf.shape[0]\n",
        "            conf = pd.concat([conf, pd.DataFrame(np.zeros((pad_rows, conf.shape[1])), columns=conf.columns)], ignore_index=True)\n",
        "    # Concatenate along columns\n",
        "    design_matrix = pd.concat([design_matrix.reset_index(drop=True), conf.reset_index(drop=True)], axis=1)\n",
        "    print(f'Added confounds to design matrix: {list(conf.columns)[:6]}...')\n",
        "ax = plot_design_matrix(design_matrix)\n",
        "ax.set_title('Design matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig(op.join(OUTPUT_DIR, 'design_matrix.png'), dpi=150)\n",
        "plt.show()\n",
        "design_matrix.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. First-level GLM and statistical maps\n",
        "We fit a `FirstLevelModel` with the above design matrix and produce z-maps for each task regressor (trial_type).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fmri_glm = FirstLevelModel(\n",
        "    t_r=TR,\n",
        "    noise_model='ar1',\n",
        "    standardize=False,\n",
        "    hrf_model='spm',\n",
        "    drift_model='cosine',\n",
        "    high_pass=0.01\n",
        ")\n",
        "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=[design_matrix])\n",
        "\n",
        "# Identify task regressors (exclude drift/cosine columns)\n",
        "task_cols = [c for c in design_matrix.columns if c not in ('constant',) and not c.startswith('drift')]\n",
        "print('Task regressors:', task_cols)\n",
        "\n",
        "zmap_paths = {}\n",
        "for col in task_cols:\n",
        "    zmap = fmri_glm.compute_contrast(col, output_type='z_score')\n",
        "    out_nii = op.join(OUTPUT_DIR, f'zmap_{col}.nii.gz')\n",
        "    zmap.to_filename(out_nii)\n",
        "    zmap_paths[col] = out_nii\n",
        "    display = plotting.plot_stat_map(\n",
        "        zmap, bg_img=load_mni152_template(), threshold=3.1, display_mode='z', cut_coords=7,\n",
        "        title=f'Z-map: {col}'\n",
        "    )\n",
        "    display.savefig(op.join(OUTPUT_DIR, f'zmap_{col}.png'))\n",
        "    display.close()\n",
        "zmap_paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hand vs. Foot contrast\n",
        "We define a contrast averaging left/right hands vs. left/right feet, in line with the lab’s design.\n",
        "If your `trial_type` naming differs, adjust the `hand_patterns` and `foot_patterns` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Auto-detect columns for hands/feet via substring match\n",
        "hand_patterns = ['hand']\n",
        "foot_patterns = ['foot']\n",
        "\n",
        "hand_cols = [c for c in task_cols if any(p.lower() in c.lower() for p in hand_patterns)]\n",
        "foot_cols = [c for c in task_cols if any(p.lower() in c.lower() for p in foot_patterns)]\n",
        "print('Detected hand columns:', hand_cols)\n",
        "print('Detected foot columns:', foot_cols)\n",
        "assert hand_cols and foot_cols, 'Could not detect hand/foot columns. Please adjust patterns.'\n",
        "\n",
        "# Build contrast as dict over design columns\n",
        "contrast_def = {c: 0.0 for c in design_matrix.columns}\n",
        "for c in hand_cols:\n",
        "    contrast_def[c] += 1.0 / len(hand_cols)\n",
        "for c in foot_cols:\n",
        "    contrast_def[c] -= 1.0 / len(foot_cols)\n",
        "\n",
        "# Remove drift entries (remain 0)\n",
        "hand_vs_foot_z = fmri_glm.compute_contrast(contrast_def, output_type='z_score')\n",
        "contrast_nii = op.join(OUTPUT_DIR, 'zmap_hand_vs_foot.nii.gz')\n",
        "hand_vs_foot_z.to_filename(contrast_nii)\n",
        "display = plotting.plot_stat_map(\n",
        "    hand_vs_foot_z, bg_img=load_mni152_template(), threshold=3.1, display_mode='z', cut_coords=7,\n",
        "    title='Hand > Foot (Z)'\n",
        ")\n",
        "display.savefig(op.join(OUTPUT_DIR, 'zmap_hand_vs_foot.png'))\n",
        "display.close()\n",
        "print('Contrast saved to:', contrast_nii)\n",
        "contrast_def\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Overlay with AAL atlas and report regions\n",
        "We overlay the contrast map with AAL parcellation and compute mean z-value per region, reporting regions with maximal contrast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch AAL atlas and resample to functional image space\n",
        "aal = fetch_atlas_aal()\n",
        "atlas_img = nib.load(aal['maps']) if isinstance(aal['maps'], str) else aal['maps']\n",
        "atlas_res = image.resample_to_img(atlas_img, fmri_img, interpolation='nearest')\n",
        "labels = list(aal['labels'])\n",
        "\n",
        "# Compute region-wise mean z from the contrast map\n",
        "masker = NiftiLabelsMasker(labels_img=atlas_res, standardize=False)\n",
        "reg_vals = masker.fit_transform(hand_vs_foot_z)  # shape (1, n_regions)\n",
        "reg_vals = reg_vals.ravel()\n",
        "\n",
        "region_df = pd.DataFrame({'label': labels, 'z': reg_vals})\n",
        "region_df_sorted = region_df.sort_values('z', ascending=False)\n",
        "region_df_sorted.to_csv(op.join(OUTPUT_DIR, 'regions_hand_vs_foot_AAL.csv'), index=False)\n",
        "\n",
        "print('Top positive regions (Hand > Foot):')\n",
        "display(region_df_sorted.head(10))\n",
        "print('Top negative regions (Foot > Hand):')\n",
        "display(region_df_sorted.tail(10))\n",
        "\n",
        "# Visualization: add AAL as translucent overlay on contrast map\n",
        "disp = plotting.plot_stat_map(\n",
        "    hand_vs_foot_z, bg_img=load_mni152_template(), threshold=3.1, display_mode='z', cut_coords=7,\n",
        "    title='Hand > Foot (Z) with AAL overlay'\n",
        ")\n",
        "disp.add_overlay(atlas_res, cmap='tab20', alpha=0.15)\n",
        "disp.savefig(op.join(OUTPUT_DIR, 'zmap_hand_vs_foot_with_AAL.png'))\n",
        "disp.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reporting Notes (for your write-up)\n",
        "- Design matrix: include the saved `design_matrix.png`. Describe conditions and drift.\n",
        "- GLM: report z-maps for each task regressor saved as `zmap_<regressor>.png`.\n",
        "- Contrast: report the vector weights (printed above) and show `zmap_hand_vs_foot.png`.\n",
        "- AAL overlay: show `zmap_hand_vs_foot_with_AAL.png` and list top regions from `regions_hand_vs_foot_AAL.csv`.\n",
        "- Methods match Week05 lab: nilearn FirstLevelModel with `hrf_model='spm'`, `noise_model='ar1'`, `drift_model='cosine'`, `high_pass=0.01`.\n",
        "\n",
        "If you included motion regressors or censored volumes, add them as additional columns in the design matrix (as in the lab) before fitting.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
